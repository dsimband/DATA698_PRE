{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f8f4f4-4171-44c8-bd9d-58cfee12d8d1",
   "metadata": {},
   "source": [
    "Links\n",
    "\n",
    "https://notebook.community/pombredanne/gensim/docs/notebooks/ldaseqmodel\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/dtm_example.ipynb\n",
    "\n",
    "https://deepnote.com/workspace/first-deepnote-workspace-f527-ed9b-a85a7f85-3f6d-4f29-ba3f-8f29b3c555fe/project/gensim-1f425538-54de-41ab-b117-339019a0b104/%2Fdocs%2Fnotebooks%2Fdtm_example.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c07d94f-72f4-4d73-adda-b922204efc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "\n",
    "import spacy\n",
    "import scattertext as st\n",
    "from scattertext.termranking import AbsoluteFrequencyRanker\n",
    "\n",
    "from FedTools import FederalReserveMins\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bff7f5d1-1c90-4903-b214-8482233b3bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0007b98-436f-416b-84bc-f3ef0ee7d751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "996329ea-3e97-4ec8-b8f7-bba5df3e7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "    Stems the given token using the PorterStemmer from the nltk library\n",
    "    Input: a single token\n",
    "    Output: the stem of the token\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_word = ps.stem(token)\n",
    "    return stemmed_word\n",
    "\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\"Converts Penn Treebank tags to WordNet.\"\"\"\n",
    "    morphy_tag = {\"NN\": \"n\", \"JJ\": \"a\", \"VB\": \"v\", \"RB\": \"r\"}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return \"n\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def lemmatize_token(token):\n",
    "    \"\"\"\n",
    "    Lemmatize the token using nltk library\n",
    "    Input: a single token\n",
    "    Output: the lemmatization of the token\n",
    "    \"\"\"\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    token_tagged = pos_tag([token])\n",
    "    tag = token_tagged[0][1]\n",
    "    morphy_tag = penn2morphy(tag)\n",
    "    lemmatized_word = wordnet.lemmatize(token, pos=morphy_tag)\n",
    "    return lemmatized_word\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_common_words(words):\n",
    "    common_words = [\n",
    "        \"first\",\n",
    "        \"like\",\n",
    "        \"welcome\",\n",
    "        \"pleased\",\n",
    "        \"let\",\n",
    "        \"good\",\n",
    "        \"afternoon\",\n",
    "        \"press\",\n",
    "        \"conference\",\n",
    "        \"meeting\",\n",
    "        \"would\",\n",
    "        \"outcome\",\n",
    "        \"going\",\n",
    "        \"know\",\n",
    "        \"said\",\n",
    "        \"along\",\n",
    "        \"together\",\n",
    "        \"also\",\n",
    "        \"formally\",\n",
    "        \"meetings\",\n",
    "        \"evening\",\n",
    "        \"annual\",\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"second\",\n",
    "        \"third\",\n",
    "        \"last\",\n",
    "        \"next\",\n",
    "        \"point\",\n",
    "        \"per\",\n",
    "        \"answer\",\n",
    "        \"ask\",\n",
    "        \"say\",\n",
    "        \"said\",\n",
    "        \"mention\",\n",
    "        \"talk\",\n",
    "        \"tell\",\n",
    "        \"told\",\n",
    "        \"suggest\",\n",
    "        \"think\",\n",
    "        \"wonder\",\n",
    "        \"mean\",\n",
    "        \"understand\",\n",
    "        \"know\",\n",
    "        \"maybe\",\n",
    "        \"perhaps\",\n",
    "        \"remain\",\n",
    "        \"generally\",\n",
    "        \"thus\",\n",
    "        \"member\",\n",
    "        \"seem\",\n",
    "        \"see\",\n",
    "        \"look\",\n",
    "        \"consider\",\n",
    "        \"regard\",\n",
    "        \"include\",\n",
    "        \"hear\",\n",
    "        \"going\",\n",
    "        \"go\",\n",
    "        \"goes\",\n",
    "        \"come\",\n",
    "        \"came\",\n",
    "        \"give\",\n",
    "        \"use\",\n",
    "        \"using\",\n",
    "        \"get\",\n",
    "        \"can\",\n",
    "        \"could\",\n",
    "        \"should\",\n",
    "        \"may\",\n",
    "        \"might\",\n",
    "        \"way\",\n",
    "        \"yes\",\n",
    "        \"no\",\n",
    "        \"lot\",\n",
    "        \"bit\",\n",
    "        \"also\",\n",
    "        \"case\",\n",
    "        \"fact\",\n",
    "        \"like\",\n",
    "        \"want\",\n",
    "        \"believe\",\n",
    "        \"feel\",\n",
    "        \"actual\",\n",
    "        \"well\",\n",
    "        \"kin\",\n",
    "        \"moment\",\n",
    "        \"time\",\n",
    "        \"now\"\n",
    "    ]\n",
    "    return [word for word in words if word not in common_words]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_speech(speech):\n",
    "    \"\"\"\n",
    "    This function does the preprocessing\n",
    "    \"\"\"\n",
    "    # put all characters in lower case\n",
    "    speech[\"Text\"] = speech[\"Text\"].str.lower()\n",
    "    speech[\"Tokens\"] = speech[\"Text\"].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    # remove stop words and non-alphabetic from all the text\n",
    "    stop_word = nltk.corpus.stopwords.words(\"english\")\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(\n",
    "        lambda x: [word for word in x if (word not in stop_word) and word.isalpha()]\n",
    "    )\n",
    "    # lemmatize\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(\n",
    "        lambda x: [lemmatize_token(token) for token in x]\n",
    "    )\n",
    "    # additional filter\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(filter_common_words)\n",
    "    speech[\"Joined_Tokens\"] = speech[\"Tokens\"].apply(lambda x: \" \".join(x))\n",
    "    speech = speech.sort_values(by=\"year\").reset_index(drop=True)\n",
    "    #speech = country_code_cleanup(speech)\n",
    "    # create a scattertext object for visualization\n",
    "    speech['parse'] = speech.Joined_Tokens.apply(st.whitespace_nlp_with_sentences)\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4dd58-5a49-4f34-a4dc-fb9286094cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc2eec-697c-4b5f-ba1b-5aa2f5394cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023e84b-3623-4ba5-9c28-473f49102f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b7b740-00c6-4701-b0c2-5eea02a7fbad",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba1cc9-6e20-4c20-98d7-820eb7d5a745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fbf0b6f-6818-4276-8832-238af68d118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing links between 2015 and 2023\n",
      "Extracting Federal Reserve Minutes.\n",
      "Retrieving articles.\n",
      "..................................................................."
     ]
    }
   ],
   "source": [
    "fed_mins = FederalReserveMins(\n",
    "            main_url = 'https://www.federalreserve.gov', \n",
    "            calendar_url ='https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm',\n",
    "            start_year = 2015,        \n",
    "            historical_split = 2017,\n",
    "            verbose = True,\n",
    "            thread_num = 10)\n",
    "\n",
    "df = fed_mins.find_minutes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f323df-555a-43a0-952f-1476a2f7472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Federal_Reserve_Mins': 'Text'}, inplace=True)\n",
    "df['Date'] = df.index\n",
    "df['year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caaed381-4545-4e33-88bf-92288f52a58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-29</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-22</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text       Date  year\n",
       "2015-01-28  The Federal Reserve, the central bank of the U... 2015-01-28  2015\n",
       "2015-03-18  The Federal Reserve, the central bank of the U... 2015-03-18  2015\n",
       "2015-04-29  The Federal Reserve, the central bank of the U... 2015-04-29  2015\n",
       "2015-06-17  The Federal Reserve, the central bank of the U... 2015-06-17  2015\n",
       "2015-07-29  The Federal Reserve, the central bank of the U... 2015-07-29  2015\n",
       "...                                                       ...        ...   ...\n",
       "2022-11-02  The Federal Reserve, the central bank of the U... 2022-11-02  2022\n",
       "2022-12-14  The Federal Reserve, the central bank of the U... 2022-12-14  2022\n",
       "2023-02-01  The Federal Reserve, the central bank of the U... 2023-02-01  2023\n",
       "2023-03-22  The Federal Reserve, the central bank of the U... 2023-03-22  2023\n",
       "2023-05-03  The Federal Reserve, the central bank of the U... 2023-05-03  2023\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a57de7b7-adcb-4572-a373-d6edab4af252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df[df['year'] > 2020].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b16692-f362-40a2-b304-35e2ec857460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_slice = df_short['year'].value_counts(sort=True, normalize=False).tolist()\n",
    "time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c255fa3c-3c0d-4166-9053-bb57d1e5345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = preprocess_speech(df_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ca175-09d1-4b35-bc36-55440bc86340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07270a9b-d7e6-488b-b1de-d616e7c61a90",
   "metadata": {},
   "source": [
    "# Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b7c8d87-bd6f-4c2b-9ad2-ea82b7f861ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short['parse'] = df_short.Joined_Tokens.apply(st.whitespace_nlp_with_sentences)\n",
    "#df_2023 = df[df[\"year\"] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7873d9c-2341-4c5b-8261-4a2bb25670e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = (\n",
    "    st.CorpusWithoutCategoriesFromParsedDocuments(df_short, parsed_col=\"parse\")\n",
    "    .build()\n",
    "    .get_unigram_corpus()\n",
    ")\n",
    "corpus.remove_infrequent_words(\n",
    "    minimum_term_count=6, term_ranker=AbsoluteFrequencyRanker\n",
    ")\n",
    "corpus.get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92de13e3-c4ca-4f80-8c35-ff55339f6ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Joined_Tokens</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>2021</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>2021</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>2021</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>2021</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>2021</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Date  year  \\\n",
       "0  the federal reserve, the central bank of the u... 2021-01-27  2021   \n",
       "1  the federal reserve, the central bank of the u... 2021-03-17  2021   \n",
       "2  the federal reserve, the central bank of the u... 2021-04-28  2021   \n",
       "3  the federal reserve, the central bank of the u... 2021-06-16  2021   \n",
       "4  the federal reserve, the central bank of the u... 2021-07-28  2021   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [federal, reserve, central, bank, united, stat...   \n",
       "1  [federal, reserve, central, bank, united, stat...   \n",
       "2  [federal, reserve, central, bank, united, stat...   \n",
       "3  [federal, reserve, central, bank, united, stat...   \n",
       "4  [federal, reserve, central, bank, united, stat...   \n",
       "\n",
       "                                       Joined_Tokens  \\\n",
       "0  federal reserve central bank united state prov...   \n",
       "1  federal reserve central bank united state prov...   \n",
       "2  federal reserve central bank united state prov...   \n",
       "3  federal reserve central bank united state prov...   \n",
       "4  federal reserve central bank united state prov...   \n",
       "\n",
       "                                               parse  \n",
       "0  (federal, reserve, central, bank, united, stat...  \n",
       "1  (federal, reserve, central, bank, united, stat...  \n",
       "2  (federal, reserve, central, bank, united, stat...  \n",
       "3  (federal, reserve, central, bank, united, stat...  \n",
       "4  (federal, reserve, central, bank, united, stat...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ce30a64-bc9c-48f1-90df-a9942dd62428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [federal, reserve, central, bank, united, stat...\n",
       "1     [federal, reserve, central, bank, united, stat...\n",
       "2     [federal, reserve, central, bank, united, stat...\n",
       "3     [federal, reserve, central, bank, united, stat...\n",
       "4     [federal, reserve, central, bank, united, stat...\n",
       "5     [federal, reserve, central, bank, united, stat...\n",
       "6     [federal, reserve, central, bank, united, stat...\n",
       "7     [federal, reserve, central, bank, united, stat...\n",
       "8     [federal, reserve, central, bank, united, stat...\n",
       "9     [federal, reserve, central, bank, united, stat...\n",
       "10    [federal, reserve, central, bank, united, stat...\n",
       "11    [federal, reserve, central, bank, united, stat...\n",
       "12    [federal, reserve, central, bank, united, stat...\n",
       "13    [federal, reserve, central, bank, united, stat...\n",
       "14    [federal, reserve, central, bank, united, stat...\n",
       "15    [federal, reserve, central, bank, united, stat...\n",
       "16    [federal, reserve, central, bank, united, stat...\n",
       "17    [federal, reserve, central, bank, united, stat...\n",
       "18    [federal, reserve, central, bank, united, stat...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df_short['Tokens']\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51a3cc6f-3fa3-4207-8561-5ca5d6f1cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36ce4246-c06e-4b80-8e1f-891ffb49f2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scattertext.ParsedCorpus.ParsedCorpus at 0x296d20a90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13721228-e2e5-4088-a93d-23308b295ea2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "411cf9d4-df2a-4179-b233-077c18d8b520",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ParsedCorpus' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/TopicModel/lib/python3.10/site-packages/gensim/models/ldaseqmodel.py:142\u001b[0m, in \u001b[0;36mLdaSeqModel.__init__\u001b[0;34m(self, corpus, time_slice, id2word, alphas, num_topics, initialize, sstats, lda_model, obs_variance, chain_variance, passes, random_state, lda_inference_max_iter, em_min_iter, em_max_iter, chunksize)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ParsedCorpus' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ldaseq \u001b[38;5;241m=\u001b[39m \u001b[43mldaseqmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaSeqModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/TopicModel/lib/python3.10/site-packages/gensim/models/ldaseqmodel.py:145\u001b[0m, in \u001b[0;36mLdaSeqModel.__init__\u001b[0;34m(self, corpus, time_slice, id2word, alphas, num_topics, initialize, sstats, lda_model, obs_variance, chain_variance, passes, random_state, lda_inference_max_iter, em_min_iter, em_max_iter, chunksize)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput corpus stream has no len(); counting documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m corpus)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_slice \u001b[38;5;241m=\u001b[39m time_slice\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ParsedCorpus' object is not iterable"
     ]
    }
   ],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002df6b-3872-456e-b03b-7467aae104ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c809b-1333-4ddc-948e-bf5e7b97db95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb459b-f641-46d1-8feb-0bc48b83a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9bfce-f58f-43be-9f02-7f308d12ccaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73266c1b-2a22-4d60-a9fd-0591b8884ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7bf68a3-e145-46d5-a821-0ef0edc157a5",
   "metadata": {},
   "source": [
    "# stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70b3071a-05b6-45f0-8f15-6afa2f93baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsimbandumwe/anaconda3/envs/TopicModel/lib/python3.10/site-packages/gensim/models/ldaseqmodel.py:298: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.models import LdaSeqModel\n",
    "\n",
    "ldaseq = LdaSeqModel(corpus=common_corpus, time_slice=[2, 4, 3], num_topics=2, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9792613-113c-4035-be76-569286ce516f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldaseqmodel.LdaSeqModel at 0x1779ba980>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2a78d-e31f-4e2c-bebf-7ed6c9fd2cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39419b4e-5957-4a95-9288-f695c8519706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "365add9d-c7f6-4f02-9af3-2d64291b5c2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel, LdaModel, LsiModel, HdpModel\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LdaMallet\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031e7e6-e4ea-4b50-bccf-37dbc1d4e865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c53d5f-5609-4e07-b6e9-f12c9519c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = './src/mallet-2.0.8/bin/mallet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c5b4c98-c84d-4d55-ab89-78c13050b0c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLdaMallet\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "import gensim.models.wrappers.LdaMallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3c3ef-afba-4042-847d-bc6824eca09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ce969a-2c78-4390-a1b6-8a6a1bb78ec5",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e192e0b9-f0ca-4a0b-a736-5034e9953f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Essentials\n",
    "import base64\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datapane as dp\n",
    "#dp.login(token='INSERT_TOKEN_HERE')\n",
    "# Gensim and LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "# NLP stuff\n",
    "import contractions\n",
    "import demoji\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('wordnet')\n",
    "import spacy\n",
    "# Plotting tools\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Miscellaneous\n",
    "from sklearn.manifold import TSNE\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df80b60-f746-4b9e-ad90-1d5f64477289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FedTools import FederalReserveMins\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a55cd2-5512-4b75-9121-e80b12a395b7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075d9477-b0e4-466d-b1f4-89f60b1177d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_col):\n",
    "    \"\"\"This function will apply NLP preprocessing lambda functions over a pandas series such as df['text'].\n",
    "       These functions include converting text to lowercase, removing emojis, expanding contractions, removing punctuation,\n",
    "       removing numbers, removing stopwords, lemmatization, etc.\"\"\"\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text_col = text_col.apply(lambda x: ' '.join([w.lower() for w in x.split()]))\n",
    "    \n",
    "    # remove emojis\n",
    "    text_col = text_col.apply(lambda x: demoji.replace(x, \"\"))\n",
    "    \n",
    "    # expand contractions  \n",
    "    text_col = text_col.apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "\n",
    "    # remove punctuation\n",
    "    text_col = text_col.apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n",
    "    \n",
    "    # remove numbers\n",
    "    text_col = text_col.apply(lambda x: ' '.join(re.sub(\"[^a-zA-Z]+\", \" \", x).split()))\n",
    "\n",
    "    # remove stopwords\n",
    "    stopwords = [sw for sw in nltk.corpus.stopwords.words('english') if sw not in ['not', 'no']]\n",
    "    text_col = text_col.apply(lambda x: ' '.join([w for w in x.split() if w not in stopwords]))\n",
    "\n",
    "    # lemmatization\n",
    "    text_col = text_col.apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(w) for w in x.split()]))\n",
    "\n",
    "    # remove short words\n",
    "    text_col = text_col.apply(lambda x: ' '.join([w.strip() for w in x.split() if len(w.strip()) >= 3]))\n",
    "\n",
    "    return text_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddba0fb-9375-48de-8dcc-42c4f10db78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb54a6-3b2c-4171-8bec-b42a5c6d170f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0518b0d-efa6-4ed7-b54a-b45b83a09b91",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d135e58-976a-4504-9821-da17ad61c04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing links between 2015 and 2023\n",
      "Extracting Federal Reserve Minutes.\n",
      "Retrieving articles.\n",
      "..................................................................."
     ]
    }
   ],
   "source": [
    "fed_mins = FederalReserveMins(\n",
    "            main_url = 'https://www.federalreserve.gov', \n",
    "            calendar_url ='https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm',\n",
    "            start_year = 2015,        \n",
    "            historical_split = 2017,\n",
    "            verbose = True,\n",
    "            thread_num = 10)\n",
    "\n",
    "df = fed_mins.find_minutes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "637cc93f-6f05-4b0e-a6fd-383926904c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'Federal_Reserve_Mins': 'Text', 'index':'Date'}, inplace=True)\n",
    "df['year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687592c7-e072-4d14-81bc-a119e7b31b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  year\n",
       "0  2015-01-28  The Federal Reserve, the central bank of the U...  2015\n",
       "1  2015-03-18  The Federal Reserve, the central bank of the U...  2015\n",
       "2  2015-04-29  The Federal Reserve, the central bank of the U...  2015\n",
       "3  2015-06-17  The Federal Reserve, the central bank of the U...  2015\n",
       "4  2015-07-29  The Federal Reserve, the central bank of the U...  2015\n",
       "..        ...                                                ...   ...\n",
       "62 2022-11-02  The Federal Reserve, the central bank of the U...  2022\n",
       "63 2022-12-14  The Federal Reserve, the central bank of the U...  2022\n",
       "64 2023-02-01  The Federal Reserve, the central bank of the U...  2023\n",
       "65 2023-03-22  The Federal Reserve, the central bank of the U...  2023\n",
       "66 2023-05-03  The Federal Reserve, the central bank of the U...  2023\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8fdf9f1-dc6f-47fd-ace6-72aeeb59ddb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['Text'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "121e42fb-880e-4cfe-a2a4-ef0047d75191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'the',\n",
       " 'central',\n",
       " 'bank',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'provides',\n",
       " 'the',\n",
       " 'nation',\n",
       " 'with',\n",
       " 'a',\n",
       " 'safe',\n",
       " 'flexible',\n",
       " 'and',\n",
       " 'stable',\n",
       " 'monetary',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'system',\n",
       " 'Federal',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Committee',\n",
       " 'Monetary',\n",
       " 'Policy',\n",
       " 'Principles',\n",
       " 'and',\n",
       " 'Practice',\n",
       " 'Policy',\n",
       " 'Implementation',\n",
       " 'Reports',\n",
       " 'Review',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Policy',\n",
       " 'Strategy',\n",
       " 'Tools',\n",
       " 'and',\n",
       " 'Communications',\n",
       " 'Institution',\n",
       " 'Supervision',\n",
       " 'Reports',\n",
       " 'Reporting',\n",
       " 'Forms',\n",
       " 'Supervision',\n",
       " 'Regulation',\n",
       " 'Letters',\n",
       " 'Banking',\n",
       " 'Applications',\n",
       " 'Legal',\n",
       " 'Developments',\n",
       " 'Regulatory',\n",
       " 'Resources',\n",
       " 'Banking',\n",
       " 'Data',\n",
       " 'Structure',\n",
       " 'Financial',\n",
       " 'Stability',\n",
       " 'Assessments',\n",
       " 'Financial',\n",
       " 'Stability',\n",
       " 'Coordination',\n",
       " 'Actions',\n",
       " 'Reports',\n",
       " 'Regulations',\n",
       " 'Statutes',\n",
       " 'Payment',\n",
       " 'Policies',\n",
       " 'Reserve',\n",
       " 'Bank',\n",
       " 'Payment',\n",
       " 'Services',\n",
       " 'Data',\n",
       " 'Financial',\n",
       " 'Market',\n",
       " 'Utilities',\n",
       " 'Infrastructures',\n",
       " 'Research',\n",
       " 'Committees',\n",
       " 'and',\n",
       " 'Forums',\n",
       " 'Working',\n",
       " 'Papers',\n",
       " 'and',\n",
       " 'Notes',\n",
       " 'Data',\n",
       " 'Models',\n",
       " 'and',\n",
       " 'Tools',\n",
       " 'Bank',\n",
       " 'Assets',\n",
       " 'and',\n",
       " 'Liabilities',\n",
       " 'Bank',\n",
       " 'Structure',\n",
       " 'Data',\n",
       " 'Business',\n",
       " 'Finance',\n",
       " 'Dealer',\n",
       " 'Financing',\n",
       " 'Terms',\n",
       " 'Exchange',\n",
       " 'Rates',\n",
       " 'and',\n",
       " 'International',\n",
       " 'Data',\n",
       " 'Financial',\n",
       " 'Accounts',\n",
       " 'Household',\n",
       " 'Finance',\n",
       " 'Industrial',\n",
       " 'Activity',\n",
       " 'Interest',\n",
       " 'Rates',\n",
       " 'Micro',\n",
       " 'Data',\n",
       " 'Reference',\n",
       " 'Manual',\n",
       " 'MDRM',\n",
       " 'Money',\n",
       " 'Stock',\n",
       " 'and',\n",
       " 'Reserve',\n",
       " 'Balances',\n",
       " 'Other',\n",
       " 'Regulations',\n",
       " 'Supervision',\n",
       " 'Enforcement',\n",
       " 'Community',\n",
       " 'Development',\n",
       " 'Research',\n",
       " 'Analysis',\n",
       " 'Consumer',\n",
       " 'Resources',\n",
       " 'June',\n",
       " '16',\n",
       " '17',\n",
       " '2015',\n",
       " 'A',\n",
       " 'meeting',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Committee',\n",
       " 'was',\n",
       " 'held',\n",
       " 'in',\n",
       " 'the',\n",
       " 'offices',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'System',\n",
       " 'in',\n",
       " 'Washington',\n",
       " 'D',\n",
       " 'C',\n",
       " 'on',\n",
       " 'Tuesday',\n",
       " 'June',\n",
       " '16',\n",
       " '2015',\n",
       " 'at',\n",
       " '1',\n",
       " '00',\n",
       " 'p',\n",
       " 'm',\n",
       " 'and',\n",
       " 'continued',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " 'June',\n",
       " '17',\n",
       " '2015',\n",
       " 'at',\n",
       " '9',\n",
       " '00',\n",
       " 'a',\n",
       " 'm',\n",
       " 'PRESENT',\n",
       " 'Janet',\n",
       " 'L',\n",
       " 'Yellen',\n",
       " 'Chair',\n",
       " 'William',\n",
       " 'C',\n",
       " 'Dudley',\n",
       " 'Vice',\n",
       " 'Chairman',\n",
       " 'Lael',\n",
       " 'Brainard',\n",
       " 'Charles',\n",
       " 'L',\n",
       " 'Evans',\n",
       " 'Stanley',\n",
       " 'Fischer',\n",
       " 'Jeffrey',\n",
       " 'M',\n",
       " 'Lacker',\n",
       " 'Dennis',\n",
       " 'P',\n",
       " 'Lockhart',\n",
       " 'Jerome',\n",
       " 'H',\n",
       " 'Powell',\n",
       " 'Daniel',\n",
       " 'K',\n",
       " 'Tarullo',\n",
       " 'John',\n",
       " 'C',\n",
       " 'Williams',\n",
       " 'James',\n",
       " 'Bullard',\n",
       " 'Esther',\n",
       " 'L',\n",
       " 'George',\n",
       " 'Loretta',\n",
       " 'J',\n",
       " 'Mester',\n",
       " 'and',\n",
       " 'Eric',\n",
       " 'Rosengren',\n",
       " 'Alternate',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Committee',\n",
       " 'Narayana',\n",
       " 'Kocherlakota',\n",
       " 'President',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Bank',\n",
       " 'of',\n",
       " 'Minneapolis',\n",
       " 'Helen',\n",
       " 'E',\n",
       " 'Holcomb',\n",
       " 'and',\n",
       " 'Blake',\n",
       " 'Prichard',\n",
       " 'First',\n",
       " 'Vice',\n",
       " 'Presidents',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Banks',\n",
       " 'of',\n",
       " 'Dallas',\n",
       " 'and',\n",
       " 'Philadelphia',\n",
       " 'respectively',\n",
       " 'Brian',\n",
       " 'F',\n",
       " 'Madigan',\n",
       " 'Secretary',\n",
       " 'Matthew',\n",
       " 'M',\n",
       " 'Luecke',\n",
       " 'Deputy',\n",
       " 'Secretary',\n",
       " 'David',\n",
       " 'W',\n",
       " 'Skidmore',\n",
       " 'Assistant',\n",
       " 'Secretary',\n",
       " 'Michelle',\n",
       " 'A',\n",
       " 'Smith',\n",
       " 'Assistant',\n",
       " 'Secretary',\n",
       " 'Scott',\n",
       " 'G',\n",
       " 'Alvarez',\n",
       " 'General',\n",
       " 'Counsel',\n",
       " 'Thomas',\n",
       " 'C',\n",
       " 'Baxter',\n",
       " 'Deputy',\n",
       " 'General',\n",
       " 'Counsel',\n",
       " 'Steven',\n",
       " 'B',\n",
       " 'Kamin',\n",
       " 'Economist',\n",
       " 'Thomas',\n",
       " 'Laubach',\n",
       " 'Economist',\n",
       " 'David',\n",
       " 'W',\n",
       " 'Wilcox',\n",
       " 'Economist',\n",
       " 'David',\n",
       " 'Altig',\n",
       " 'Eric',\n",
       " 'M',\n",
       " 'Engen',\n",
       " '1',\n",
       " 'Michael',\n",
       " 'P',\n",
       " 'Leahy',\n",
       " 'Jonathan',\n",
       " 'P',\n",
       " 'McCarthy',\n",
       " 'William',\n",
       " 'R',\n",
       " 'Nelson',\n",
       " 'Glenn',\n",
       " 'D',\n",
       " 'Rudebusch',\n",
       " 'and',\n",
       " 'William',\n",
       " 'Wascher',\n",
       " 'Associate',\n",
       " 'Economists',\n",
       " 'Simon',\n",
       " 'Potter',\n",
       " 'Manager',\n",
       " 'System',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Account',\n",
       " 'Lorie',\n",
       " 'K',\n",
       " 'Logan',\n",
       " 'Deputy',\n",
       " 'Manager',\n",
       " 'System',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Account',\n",
       " 'Robert',\n",
       " 'deV',\n",
       " 'Frierson',\n",
       " '2',\n",
       " 'Secretary',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Secretary',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Michael',\n",
       " 'S',\n",
       " 'Gibson',\n",
       " 'Director',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Banking',\n",
       " 'Supervision',\n",
       " 'and',\n",
       " 'Regulation',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'James',\n",
       " 'A',\n",
       " 'Clouse',\n",
       " 'and',\n",
       " 'Stephen',\n",
       " 'A',\n",
       " 'Meyer',\n",
       " 'Deputy',\n",
       " 'Directors',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Daniel',\n",
       " 'M',\n",
       " 'Covitz',\n",
       " 'Deputy',\n",
       " 'Director',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Research',\n",
       " 'and',\n",
       " 'Statistics',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Andreas',\n",
       " 'Lehnert',\n",
       " 'Deputy',\n",
       " 'Director',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'Financial',\n",
       " 'Stability',\n",
       " 'Policy',\n",
       " 'and',\n",
       " 'Research',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'William',\n",
       " 'B',\n",
       " 'English',\n",
       " 'Senior',\n",
       " 'Special',\n",
       " 'Adviser',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'Board',\n",
       " 'Members',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'David',\n",
       " 'Bowman',\n",
       " 'Andrew',\n",
       " 'Figura',\n",
       " 'David',\n",
       " 'Reifschneider',\n",
       " 'and',\n",
       " 'Stacey',\n",
       " 'Tevlin',\n",
       " 'Special',\n",
       " 'Advisers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'Board',\n",
       " 'Members',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Trevor',\n",
       " 'A',\n",
       " 'Reeve',\n",
       " 'Special',\n",
       " 'Adviser',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Chair',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'Board',\n",
       " 'Members',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Linda',\n",
       " 'Robertson',\n",
       " 'Assistant',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'Board',\n",
       " 'Members',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Christopher',\n",
       " 'J',\n",
       " 'Erceg',\n",
       " 'and',\n",
       " 'Beth',\n",
       " 'Anne',\n",
       " 'Wilson',\n",
       " 'Senior',\n",
       " 'Associate',\n",
       " 'Directors',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'International',\n",
       " 'Finance',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'David',\n",
       " 'E',\n",
       " 'Lebow',\n",
       " 'and',\n",
       " 'Michael',\n",
       " 'G',\n",
       " 'Palumbo',\n",
       " 'Senior',\n",
       " 'Associate',\n",
       " 'Directors',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Research',\n",
       " 'and',\n",
       " 'Statistics',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Ellen',\n",
       " 'E',\n",
       " 'Meade',\n",
       " 'and',\n",
       " 'Joyce',\n",
       " 'K',\n",
       " 'Zickler',\n",
       " 'Senior',\n",
       " 'Advisers',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Gretchen',\n",
       " 'C',\n",
       " 'Weinbach',\n",
       " 'Associate',\n",
       " 'Director',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Jane',\n",
       " 'E',\n",
       " 'Ihrig',\n",
       " 'Deputy',\n",
       " 'Associate',\n",
       " 'Director',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Glenn',\n",
       " 'Follette',\n",
       " 'and',\n",
       " 'Paul',\n",
       " 'A',\n",
       " 'Smith',\n",
       " 'Assistant',\n",
       " 'Directors',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Research',\n",
       " 'and',\n",
       " 'Statistics',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Robert',\n",
       " 'J',\n",
       " 'Tetlow',\n",
       " 'Adviser',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Penelope',\n",
       " 'A',\n",
       " 'Beattie',\n",
       " '2',\n",
       " 'Assistant',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Secretary',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Secretary',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Katie',\n",
       " 'Ross',\n",
       " '2',\n",
       " 'Manager',\n",
       " 'Office',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Secretary',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'David',\n",
       " 'H',\n",
       " 'Small',\n",
       " 'Project',\n",
       " 'Manager',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Stephen',\n",
       " 'Lin',\n",
       " 'Senior',\n",
       " 'Economist',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'International',\n",
       " 'Finance',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Deborah',\n",
       " 'J',\n",
       " 'Lindner',\n",
       " 'Senior',\n",
       " 'Economist',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Research',\n",
       " 'and',\n",
       " 'Statistics',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Benjamin',\n",
       " 'K',\n",
       " 'Johannsen',\n",
       " 'Marcel',\n",
       " 'A',\n",
       " 'Priebsch',\n",
       " 'and',\n",
       " 'Francisco',\n",
       " 'Vazquez',\n",
       " 'Grande',\n",
       " '3',\n",
       " 'Economists',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Randall',\n",
       " 'A',\n",
       " 'Williams',\n",
       " 'Information',\n",
       " 'Management',\n",
       " 'Analyst',\n",
       " 'Division',\n",
       " 'of',\n",
       " 'Monetary',\n",
       " 'Affairs',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'Mark',\n",
       " 'A',\n",
       " 'Gould',\n",
       " 'First',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Bank',\n",
       " 'of',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'Michael',\n",
       " 'Strine',\n",
       " 'Executive',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Bank',\n",
       " 'of',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Kartik',\n",
       " 'B',\n",
       " 'Athreya',\n",
       " 'Evan',\n",
       " 'F',\n",
       " 'Koenig',\n",
       " 'Susan',\n",
       " 'McLaughlin',\n",
       " '3',\n",
       " 'Samuel',\n",
       " 'Schulhofer',\n",
       " 'Wohl',\n",
       " 'Ellis',\n",
       " 'W',\n",
       " 'Tallman',\n",
       " 'Geoffrey',\n",
       " 'Tootell',\n",
       " 'and',\n",
       " 'Christopher',\n",
       " 'J',\n",
       " 'Waller',\n",
       " 'Senior',\n",
       " 'Vice',\n",
       " 'Presidents',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Banks',\n",
       " 'of',\n",
       " 'Richmond',\n",
       " 'Dallas',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Minneapolis',\n",
       " 'Cleveland',\n",
       " 'Boston',\n",
       " 'and',\n",
       " 'St',\n",
       " 'Louis',\n",
       " 'respectively',\n",
       " 'Roc',\n",
       " 'Armenter',\n",
       " 'Deborah',\n",
       " 'L',\n",
       " 'Leonard',\n",
       " 'Anna',\n",
       " 'Paulson',\n",
       " 'Douglas',\n",
       " 'Tillett',\n",
       " 'and',\n",
       " 'Jonathan',\n",
       " 'L',\n",
       " 'Willis',\n",
       " 'Vice',\n",
       " 'Presidents',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Banks',\n",
       " 'of',\n",
       " 'Philadelphia',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Chicago',\n",
       " 'Chicago',\n",
       " 'and',\n",
       " 'Kansas',\n",
       " 'City',\n",
       " 'respectively',\n",
       " 'Developments',\n",
       " 'in',\n",
       " 'Financial',\n",
       " 'Markets',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 's',\n",
       " 'Balance',\n",
       " 'Sheet',\n",
       " 'In',\n",
       " 'a',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Committee',\n",
       " 'FOMC',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'Governors',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'System',\n",
       " 'the',\n",
       " 'manager',\n",
       " 'of',\n",
       " 'the',\n",
       " 'System',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Account',\n",
       " 'SOMA',\n",
       " 'reported',\n",
       " 'on',\n",
       " 'developments',\n",
       " 'in',\n",
       " 'domestic',\n",
       " 'and',\n",
       " 'foreign',\n",
       " 'financial',\n",
       " 'markets',\n",
       " 'The',\n",
       " 'manager',\n",
       " 'also',\n",
       " 'discussed',\n",
       " 'System',\n",
       " 'open',\n",
       " 'market',\n",
       " 'operations',\n",
       " 'conducted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Open',\n",
       " 'Market',\n",
       " 'Desk',\n",
       " 'during',\n",
       " 'the',\n",
       " 'period',\n",
       " 'since',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'met',\n",
       " 'on',\n",
       " 'April',\n",
       " '28',\n",
       " '29',\n",
       " 'The',\n",
       " 'Desk',\n",
       " 's',\n",
       " 'overnight',\n",
       " 'reverse',\n",
       " 'repurchase',\n",
       " 'agreement',\n",
       " 'RRP',\n",
       " 'operations',\n",
       " 'continued',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'a',\n",
       " 'soft',\n",
       " 'floor',\n",
       " 'for',\n",
       " 'money',\n",
       " 'market',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'The',\n",
       " 'manager',\n",
       " 'updated',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'on',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'term',\n",
       " 'RRP',\n",
       " 'operations',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'second',\n",
       " 'quarter',\n",
       " 'and',\n",
       " 'noted',\n",
       " 'that',\n",
       " 'testing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 's',\n",
       " 'Term',\n",
       " 'Deposit',\n",
       " 'Facility',\n",
       " 'continued',\n",
       " 'The',\n",
       " 'manager',\n",
       " 'also',\n",
       " 'reviewed',\n",
       " 'the',\n",
       " 'reinvestment',\n",
       " 'policy',\n",
       " 'for',\n",
       " 'maturing',\n",
       " 'Treasury',\n",
       " 'securities',\n",
       " 'Specifically',\n",
       " 'at',\n",
       " 'Treasury',\n",
       " 'auctions',\n",
       " 'the',\n",
       " 'Desk',\n",
       " 'rolls',\n",
       " 'over',\n",
       " 'the',\n",
       " 'maturing',\n",
       " 'securities',\n",
       " 'held',\n",
       " 'in',\n",
       " 'the',\n",
       " 'SOMA',\n",
       " 'into',\n",
       " 'newly',\n",
       " 'issued',\n",
       " 'securities',\n",
       " 'in',\n",
       " 'proportion',\n",
       " 'to',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'new',\n",
       " 'securities',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'receives',\n",
       " 'the',\n",
       " 'interest',\n",
       " 'rate',\n",
       " 'determined',\n",
       " 'competitively',\n",
       " 'in',\n",
       " 'the',\n",
       " 'public',\n",
       " 'auction',\n",
       " 'of',\n",
       " 'the',\n",
       " 'newly',\n",
       " 'issued',\n",
       " 'securities',\n",
       " 'The',\n",
       " 'manager',\n",
       " 'updated',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'on',\n",
       " 'tentative',\n",
       " 'plans',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'calculation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'effective',\n",
       " 'federal',\n",
       " 'funds',\n",
       " 'rate',\n",
       " 'published',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Reserve',\n",
       " 'Bank',\n",
       " 'of',\n",
       " 'New',\n",
       " 'York',\n",
       " 'The',\n",
       " 'effective',\n",
       " 'federal',\n",
       " 'funds',\n",
       " 'rate',\n",
       " 'currently',\n",
       " 'defined',\n",
       " 'as',\n",
       " 'the',\n",
       " 'volume',\n",
       " 'weighted',\n",
       " 'mean',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'on',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(df['Text'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f3a7d-c1b8-45c4-aa87-5101422b6509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d9d60-0767-43c9-903b-772f083f9d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c44133-90cc-449f-95d8-8b2d83cae892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42613791-4777-45c1-93c4-284f1ae3968b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m id2word \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary(\u001b[43mdata_preprocessed\u001b[49m)\n\u001b[1;32m      2\u001b[0m id2word\u001b[38;5;241m.\u001b[39mfilter_extremes(no_below\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, no_above\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, keep_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_preprocessed)\n",
    "id2word.filter_extremes(no_below=15, no_above=0.4, keep_n=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a6b90-1aeb-45c3-ae62-a3395b42eeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead1b98-008f-45d6-a6de-66a60fc86edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac8703-9257-4576-bb8d-af7679350e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd01d2-7987-4572-a9d0-6dc5ba8b5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa2042-94a9-40d1-92b0-b5ff556d8935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "116cfadc-8461-4ed1-937a-8bf131591f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<40 unique tokens: ['end-to-end', 'find', 'projectpro', 'projects', 'different']...>\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "\n",
    "\n",
    "#creating a sample corpus for demonstration purpose\n",
    "txt_corpus = [\n",
    "\n",
    "    \"Find end-to-end projects at ProjectPro\",\n",
    "\n",
    "    \"Stop wasting time on different online forums to get your project solutions\",\n",
    "\n",
    "    \"Each of our projects solve a real business problem from start to finish\",\n",
    "\n",
    "    \"All projects come with downloadable solution code and explanatory videos\",\n",
    "\n",
    "    \"All our projects are designed modularly so you can rapidly learn and reuse modules\"]\n",
    "\n",
    "\n",
    "\n",
    "# Creating a set of frequent words\n",
    "stoplist = set('for a of the and to in on of to are at'.split(' '))\n",
    "\n",
    "\n",
    "\n",
    "# Lowercasing each document, using white space as delimiter and filtering out the stopwords\n",
    "processed_text = [[word for word in document.lower().split() if word not in stoplist]for document in txt_corpus]\n",
    "\n",
    "\n",
    "\n",
    "#creating a dictionary\n",
    "dictionary = corpora.Dictionary(processed_text)\n",
    "\n",
    "\n",
    "\n",
    "#displaying the dictionary\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfed659-d82e-4e32-891c-378d8de87114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'and', 'are', 'at', 'for', 'in', 'of', 'on', 'the', 'to'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e717b6b-1a91-44f5-a066-038b5546fa0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Find end-to-end projects at ProjectPro',\n",
       " 'Stop wasting time on different online forums to get your project solutions',\n",
       " 'Each of our projects solve a real business problem from start to finish',\n",
       " 'All projects come with downloadable solution code and explanatory videos',\n",
       " 'All our projects are designed modularly so you can rapidly learn and reuse modules']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910a910a-03e5-42d9-87ad-15f294f7c174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#processed_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
