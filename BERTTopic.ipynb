{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba60fd3-48d5-400c-b5f0-692921df2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "import spacy\n",
    "import scattertext as st\n",
    "\n",
    "from FedTools import FederalReserveMins\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80bf02-8cda-45e1-8d8f-cbefaadaf8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f892179-0315-41d5-8fb3-de0bd75decd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dsimbandumwe/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"vader_lexicon\")\n",
    "except LookupError:\n",
    "    nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29310a-9489-4285-824d-ddc6d08ff57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504ce5f-fba5-4e52-8315-2b03bd1e36c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab5571b-0086-4df5-a687-6827abfe8cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2917d76-36bf-44f1-89b3-da4bcd957c0f",
   "metadata": {},
   "source": [
    "def remove_line_number(speech):\n",
    "    \"\"\"\n",
    "    removes the line number at the beginning of speech\n",
    "    Input: str\n",
    "    Output: str\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = \"\\n|^\\d+.*?(\\w)\"\n",
    "    speech = re.sub(pattern, \"\\n\\g<1>\", speech)\n",
    "    pattern = \"\\t\"\n",
    "    speech = re.sub(pattern, \"\", speech)\n",
    "    pattern = \"\\n\\n\"\n",
    "    speech = re.sub(pattern, \"\\n\", speech)\n",
    "    pattern = \"^\\n *\"\n",
    "    speech = re.sub(pattern, \"\", speech)\n",
    "\n",
    "    return speech\n",
    "\n",
    "\n",
    "\n",
    "def remove_first_sentence(speech):\n",
    "    \"\"\"\n",
    "    remove the first sentence\n",
    "    \"\"\"\n",
    "    pattern = r\"^.*?\\.\"\n",
    "    speech = re.sub(pattern, \"\", speech)\n",
    "\n",
    "    return speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a170cc73-df02-4221-9235-1947ad2d04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "    Stems the given token using the PorterStemmer from the nltk library\n",
    "    Input: a single token\n",
    "    Output: the stem of the token\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_word = ps.stem(token)\n",
    "    return stemmed_word\n",
    "\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\"Converts Penn Treebank tags to WordNet.\"\"\"\n",
    "    morphy_tag = {\"NN\": \"n\", \"JJ\": \"a\", \"VB\": \"v\", \"RB\": \"r\"}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return \"n\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def lemmatize_token(token):\n",
    "    \"\"\"\n",
    "    Lemmatize the token using nltk library\n",
    "    Input: a single token\n",
    "    Output: the lemmatization of the token\n",
    "    \"\"\"\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    token_tagged = pos_tag([token])\n",
    "    tag = token_tagged[0][1]\n",
    "    morphy_tag = penn2morphy(tag)\n",
    "    lemmatized_word = wordnet.lemmatize(token, pos=morphy_tag)\n",
    "    return lemmatized_word\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_common_words(words):\n",
    "    common_words = [\n",
    "        \"first\",\n",
    "        \"like\",\n",
    "        \"welcome\",\n",
    "        \"pleased\",\n",
    "        \"let\",\n",
    "        \"good\",\n",
    "        \"afternoon\",\n",
    "        \"press\",\n",
    "        \"conference\",\n",
    "        \"meeting\",\n",
    "        \"would\",\n",
    "        \"outcome\",\n",
    "        \"going\",\n",
    "        \"know\",\n",
    "        \"said\",\n",
    "        \"along\",\n",
    "        \"together\",\n",
    "        \"also\",\n",
    "        \"formally\",\n",
    "        \"meetings\",\n",
    "        \"evening\",\n",
    "        \"annual\",\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"second\",\n",
    "        \"third\",\n",
    "        \"last\",\n",
    "        \"next\",\n",
    "        \"point\",\n",
    "        \"per\",\n",
    "        \"answer\",\n",
    "        \"ask\",\n",
    "        \"say\",\n",
    "        \"said\",\n",
    "        \"mention\",\n",
    "        \"talk\",\n",
    "        \"tell\",\n",
    "        \"told\",\n",
    "        \"suggest\",\n",
    "        \"think\",\n",
    "        \"wonder\",\n",
    "        \"mean\",\n",
    "        \"understand\",\n",
    "        \"know\",\n",
    "        \"maybe\",\n",
    "        \"perhaps\",\n",
    "        \"remain\",\n",
    "        \"generally\",\n",
    "        \"thus\",\n",
    "        \"member\",\n",
    "        \"seem\",\n",
    "        \"see\",\n",
    "        \"look\",\n",
    "        \"consider\",\n",
    "        \"regard\",\n",
    "        \"include\",\n",
    "        \"hear\",\n",
    "        \"going\",\n",
    "        \"go\",\n",
    "        \"goes\",\n",
    "        \"come\",\n",
    "        \"came\",\n",
    "        \"give\",\n",
    "        \"use\",\n",
    "        \"using\",\n",
    "        \"get\",\n",
    "        \"can\",\n",
    "        \"could\",\n",
    "        \"should\",\n",
    "        \"may\",\n",
    "        \"might\",\n",
    "        \"way\",\n",
    "        \"yes\",\n",
    "        \"no\",\n",
    "        \"lot\",\n",
    "        \"bit\",\n",
    "        \"also\",\n",
    "        \"case\",\n",
    "        \"fact\",\n",
    "        \"like\",\n",
    "        \"want\",\n",
    "        \"believe\",\n",
    "        \"feel\",\n",
    "        \"actual\",\n",
    "        \"well\",\n",
    "        \"kin\",\n",
    "        \"moment\",\n",
    "        \"time\",\n",
    "        \"now\"\n",
    "    ]\n",
    "    return [word for word in words if word not in common_words]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_speech(speech):\n",
    "    \"\"\"\n",
    "    This function does the preprocessing\n",
    "    \"\"\"\n",
    "    # put all characters in lower case\n",
    "    speech[\"Text\"] = speech[\"Text\"].str.lower()\n",
    "    speech[\"Tokens\"] = speech[\"Text\"].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    # remove stop words and non-alphabetic from all the text\n",
    "    stop_word = nltk.corpus.stopwords.words(\"english\")\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(\n",
    "        lambda x: [word for word in x if (word not in stop_word) and word.isalpha()]\n",
    "    )\n",
    "    # lemmatize\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(\n",
    "        lambda x: [lemmatize_token(token) for token in x]\n",
    "    )\n",
    "    # additional filter\n",
    "    speech[\"Tokens\"] = speech[\"Tokens\"].apply(filter_common_words)\n",
    "    speech[\"Joined_Tokens\"] = speech[\"Tokens\"].apply(lambda x: \" \".join(x))\n",
    "    speech = speech.sort_values(by=\"year\").reset_index(drop=True)\n",
    "    #speech = country_code_cleanup(speech)\n",
    "    # create a scattertext object for visualization\n",
    "    speech['parse'] = speech.Joined_Tokens.apply(st.whitespace_nlp_with_sentences)\n",
    "    return speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a897d-9955-4e3c-ac0e-81ee09aa5810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3222bcf-fe5b-4a69-9622-e9feeed87ce7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acce074-43d6-49aa-9a6c-8bb768dc43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing links between 2015 and 2023\n",
      "Extracting Federal Reserve Minutes.\n",
      "Retrieving articles.\n",
      "..................................................................."
     ]
    }
   ],
   "source": [
    "fed_mins = FederalReserveMins(\n",
    "            main_url = 'https://www.federalreserve.gov', \n",
    "            calendar_url ='https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm',\n",
    "            start_year = 2015,        \n",
    "            historical_split = 2017,\n",
    "            verbose = True,\n",
    "            thread_num = 10)\n",
    "\n",
    "df = fed_mins.find_minutes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e92c296-ef7b-4e33-9ba2-34d0d9571f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Federal_Reserve_Mins': 'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c120e2-bc1e-4404-9479-c2ff42cdd05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 67 entries, 2015-01-28 to 2023-05-03\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    67 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ac5ebb-0813-47e8-9bdf-edfc86fe7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25991340-a956-48ba-9d9f-178b8e1ccf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1af560-e68a-483b-b6bb-f7a57277b18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-18</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-29</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-29</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-22</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>The Federal Reserve, the central bank of the U...</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text       Date  year\n",
       "2015-01-28  The Federal Reserve, the central bank of the U... 2015-01-28  2015\n",
       "2015-03-18  The Federal Reserve, the central bank of the U... 2015-03-18  2015\n",
       "2015-04-29  The Federal Reserve, the central bank of the U... 2015-04-29  2015\n",
       "2015-06-17  The Federal Reserve, the central bank of the U... 2015-06-17  2015\n",
       "2015-07-29  The Federal Reserve, the central bank of the U... 2015-07-29  2015\n",
       "...                                                       ...        ...   ...\n",
       "2022-11-02  The Federal Reserve, the central bank of the U... 2022-11-02  2022\n",
       "2022-12-14  The Federal Reserve, the central bank of the U... 2022-12-14  2022\n",
       "2023-02-01  The Federal Reserve, the central bank of the U... 2023-02-01  2023\n",
       "2023-03-22  The Federal Reserve, the central bank of the U... 2023-03-22  2023\n",
       "2023-05-03  The Federal Reserve, the central bank of the U... 2023-05-03  2023\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749cd1c6-6e0a-4811-a18c-fa10a0bfe990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_speech(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34577c3-311d-4c02-8292-ed277a4e0988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "337b067e-3ec9-4c77-9d01-4e896daed4f4",
   "metadata": {},
   "source": [
    "# Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "089663be-1bf7-4253-8905-6968bc7e3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "from scattertext.termranking import AbsoluteFrequencyRanker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926c0a38-eee3-4803-ab05-dbadffe0a84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Joined_Tokens</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2015</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>2015</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>2015</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>2015</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>2015</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>2022</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>2022</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>the federal reserve, the central bank of the u...</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>2023</td>\n",
       "      <td>[federal, reserve, central, bank, united, stat...</td>\n",
       "      <td>federal reserve central bank united state prov...</td>\n",
       "      <td>(federal, reserve, central, bank, united, stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text       Date  year  \\\n",
       "0   the federal reserve, the central bank of the u... 2015-01-28  2015   \n",
       "1   the federal reserve, the central bank of the u... 2015-03-18  2015   \n",
       "2   the federal reserve, the central bank of the u... 2015-04-29  2015   \n",
       "3   the federal reserve, the central bank of the u... 2015-06-17  2015   \n",
       "4   the federal reserve, the central bank of the u... 2015-07-29  2015   \n",
       "..                                                ...        ...   ...   \n",
       "62  the federal reserve, the central bank of the u... 2022-11-02  2022   \n",
       "63  the federal reserve, the central bank of the u... 2022-12-14  2022   \n",
       "64  the federal reserve, the central bank of the u... 2023-03-22  2023   \n",
       "65  the federal reserve, the central bank of the u... 2023-02-01  2023   \n",
       "66  the federal reserve, the central bank of the u... 2023-05-03  2023   \n",
       "\n",
       "                                               Tokens  \\\n",
       "0   [federal, reserve, central, bank, united, stat...   \n",
       "1   [federal, reserve, central, bank, united, stat...   \n",
       "2   [federal, reserve, central, bank, united, stat...   \n",
       "3   [federal, reserve, central, bank, united, stat...   \n",
       "4   [federal, reserve, central, bank, united, stat...   \n",
       "..                                                ...   \n",
       "62  [federal, reserve, central, bank, united, stat...   \n",
       "63  [federal, reserve, central, bank, united, stat...   \n",
       "64  [federal, reserve, central, bank, united, stat...   \n",
       "65  [federal, reserve, central, bank, united, stat...   \n",
       "66  [federal, reserve, central, bank, united, stat...   \n",
       "\n",
       "                                        Joined_Tokens  \\\n",
       "0   federal reserve central bank united state prov...   \n",
       "1   federal reserve central bank united state prov...   \n",
       "2   federal reserve central bank united state prov...   \n",
       "3   federal reserve central bank united state prov...   \n",
       "4   federal reserve central bank united state prov...   \n",
       "..                                                ...   \n",
       "62  federal reserve central bank united state prov...   \n",
       "63  federal reserve central bank united state prov...   \n",
       "64  federal reserve central bank united state prov...   \n",
       "65  federal reserve central bank united state prov...   \n",
       "66  federal reserve central bank united state prov...   \n",
       "\n",
       "                                                parse  \n",
       "0   (federal, reserve, central, bank, united, stat...  \n",
       "1   (federal, reserve, central, bank, united, stat...  \n",
       "2   (federal, reserve, central, bank, united, stat...  \n",
       "3   (federal, reserve, central, bank, united, stat...  \n",
       "4   (federal, reserve, central, bank, united, stat...  \n",
       "..                                                ...  \n",
       "62  (federal, reserve, central, bank, united, stat...  \n",
       "63  (federal, reserve, central, bank, united, stat...  \n",
       "64  (federal, reserve, central, bank, united, stat...  \n",
       "65  (federal, reserve, central, bank, united, stat...  \n",
       "66  (federal, reserve, central, bank, united, stat...  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541dc0a9-ce93-498c-bcae-ec11062b0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parse'] = df.Joined_Tokens.apply(st.whitespace_nlp_with_sentences)\n",
    "df_2023 = df[df[\"year\"] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b945311-d75c-4f94-bb94-b4152ff10ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = (\n",
    "    st.CorpusWithoutCategoriesFromParsedDocuments(df_2023, parsed_col=\"parse\")\n",
    "    .build()\n",
    "    .get_unigram_corpus()\n",
    ")\n",
    "corpus.remove_infrequent_words(\n",
    "    minimum_term_count=6, term_ranker=AbsoluteFrequencyRanker\n",
    ")\n",
    "corpus.get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a6de1c3-ab3a-4b92-827d-cf5ab21ca006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Range</th>\n",
       "      <th>SD</th>\n",
       "      <th>VC</th>\n",
       "      <th>Juilland's D</th>\n",
       "      <th>Rosengren's S</th>\n",
       "      <th>DP</th>\n",
       "      <th>DP norm</th>\n",
       "      <th>KL-divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>federal</th>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>8.730534</td>\n",
       "      <td>0.141576</td>\n",
       "      <td>0.933845</td>\n",
       "      <td>0.997734</td>\n",
       "      <td>0.041285</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.006538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reserve</th>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>11.145502</td>\n",
       "      <td>0.225922</td>\n",
       "      <td>0.882404</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.080474</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.019789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>central</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>0.287820</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.987665</td>\n",
       "      <td>0.102824</td>\n",
       "      <td>0.148190</td>\n",
       "      <td>0.035789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>10.338708</td>\n",
       "      <td>0.146302</td>\n",
       "      <td>0.900468</td>\n",
       "      <td>0.995096</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>0.014305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.699673</td>\n",
       "      <td>0.637377</td>\n",
       "      <td>0.587252</td>\n",
       "      <td>0.911684</td>\n",
       "      <td>0.266285</td>\n",
       "      <td>0.383771</td>\n",
       "      <td>0.249716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency  Range         SD        VC  Juilland's D  Rosengren's S  \\\n",
       "federal        185      3   8.730534  0.141576      0.933845       0.997734   \n",
       "reserve        148      3  11.145502  0.225922      0.882404       0.993234   \n",
       "central         13      3   1.247219  0.287820      0.840253       0.987665   \n",
       "bank           212      3  10.338708  0.146302      0.900468       0.995096   \n",
       "united           8      3   1.699673  0.637377      0.587252       0.911684   \n",
       "\n",
       "               DP   DP norm  KL-divergence  \n",
       "federal  0.041285  0.059500       0.006538  \n",
       "reserve  0.080474  0.115980       0.019789  \n",
       "central  0.102824  0.148190       0.035789  \n",
       "bank     0.065794  0.094822       0.014305  \n",
       "united   0.266285  0.383771       0.249716  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispersion = st.Dispersion(corpus)\n",
    "dispersion_df = dispersion.get_df()\n",
    "dispersion_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7f59ce-89c4-4793-aef7-c9a6e6c81818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_df = dispersion_df.assign(\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df[\"Rosengren's S\"],\n",
    "    Ypos=lambda df: st.Scalers.scale(df.Y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2363da3c-eebf-4c6b-bef3-4c96df2bb0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsimbandumwe/anaconda3/envs/TopicModel/lib/python3.10/site-packages/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1420055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.dataframe_scattertext(\n",
    "    corpus,\n",
    "    plot_df=dispersion_df,\n",
    "    ignore_categories=True,\n",
    "    color_score_column=\"ColorScore\",\n",
    "    x_label=\"Log Frequency\",\n",
    "    y_label=\"Rosengren's S\",\n",
    "    y_axis_labels=[\"Less Dispersion\", \"Medium\", \"More Dispersion\"],\n",
    ")\n",
    "\n",
    "open(\"unga_dispersion.html\", \"wb\").write(html.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe27aff-fbd9-4dd6-aad8-0c0f69b22d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44e328-9e22-4093-b221-aa2b0b1e2886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a12643-f53b-43ec-a648-2a6e94d9971a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be33d5-9b0b-4691-94f1-73e2529815f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b50e72-ce1d-4fea-8119-0bd362bc565d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
